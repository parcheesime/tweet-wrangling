 ## Wrangle and Analyze Twitter Data

 **Purpose:** Record my skills and process in wrangling multiple datasets from different datasource. This project highlights and showcases samples of some of data gathering, assessing, cleaning, storing, and analyzing data.
 
 **Goal:** wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. 

 ![happy doggo](doggo,jpg "Happy ")
 
 The Twitter archive contains very basic tweet information. Additional gathering, then assessing and cleaning is required for analyses and visualizations.

Three datasets:

- Twitter_archive_enhanced.csv
- Image_predictions.tsv
    - using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv
- Get tweet retweet count, and ‘like’ count from Twitter API, tweet_json.txt
    - Using Tweepy library, https://www.tweepy.org/ 


**Project Steps Overview**

Step 1: Gathering data

Step 2: Assessing data

Step 3: Cleaning data

Step 4: Storing data

Step 5: Analyzing, and visualizing data

Step 6: Reporting
- data wrangling efforts
- data analyses and visualizations

